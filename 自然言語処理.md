---
title: 自然言語処理
---

* Encodingの歴史
  * LV1 [One-hot](One-hot.md) vector = *0,0,0,1,0,0,0* (only one 1 (hot))
  * LV2 Tf-idf = appear frequently globally => not important & apper frequently locally => important
  * LV3 Word2vec = *x,x,x* king - distance(male,female) (includes some essence tf-idf
  * LV4 BERT
    * BERT can’t understand he/she (pronouns)
      * But, it 推測 from surrounding other words (word sense disambiguation)

[https://ishitonton.hatenablog.com/entry/2018/11/25/200332](https://ishitonton.hatenablog.com/entry/2018/11/25/200332)

* embeddingについて

---

<img src='https://scrapbox.io/api/pages/blu3mo-public/情報科学の達人/icon' alt='情報科学の達人.icon' height="19.5"/>
- [[言語学]]と[[情報科学]]が重なる分野
- アプローチ
    - 人間が[[言語]]の入力/出力を行う仕組みを知りたい
    - [[脳科学]]とか使わないと脳の情報処理はわからない
    - なので、[[観測可能]]な言語を通じて仕組みを探る

* やることの一部
  
  * *機械翻訳*
  * *文章読解*
  * *テキストマイニング*: ツイート等の膨大な自然言語データーから情報を得る
* ただの言語の処理だけではない
  
  * 言語が持つ意味、知識、感情等、人間の知能に関わる深いところまで繋がる
  * <img src='https://scrapbox.io/api/pages/blu3mo-public/blu3mo/icon' alt='blu3mo.icon' height="19.5"/> イメージ以上に広い分野
* 方法論
  
  * 文字列として処理はできない　（ケヤキとケーキは文字列としては近い、意味的には全然違う）
  
  * 意味をどのように扱うか
    
    * 意味とは?: 人間が*同値*性を判定できるもの
    * （頭の中の処理は観察できないので、*観察*できる同値性の判定を用いる）
  * 「[離散構造](%E9%9B%A2%E6%95%A3%E6%A7%8B%E9%80%A0.md)」と「連続的規則性」をどう組み合わせるか
    
    * 自然言語の構造は、正誤がはっきりしている = *離散*値構造的な規則性がある
      * ex: 画像とかなら一ピクセル変えてもそんなに影響ない、でも自然言語で一文字変えると大きな問題
    * ただ、*あいまい*性、*不確実*性もある (*統計*的、*連続*値的な性質）
      * 言語のあいまい性と直結
    * つまり、*離散*的・*連続*的の複合的な性質を持つ
  * 何をコーパスから学ぶか
    
    * 自然言語テキストデーターのことを「*コーパス*」という
    * *規則性*等をコーパスから学べる
    * ex: *言語モデル* (文らしさを評価)
  * 技術として一番よく使うのはやはり[機械学習](%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92.md)

* [構文解析](%E6%A7%8B%E6%96%87%E8%A7%A3%E6%9E%90.md)
  
  * 文章の構文を理解する技術
  * 詳しく↑に書いた
* [意味解析](%E6%84%8F%E5%91%B3%E8%A7%A3%E6%9E%90.md)
  
  * 文章/単語の意味を理解する技術
  * 詳しく↑に書いた
