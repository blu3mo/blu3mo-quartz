---
title:
 'GPT-3'
---

<img src='https://scrapbox.io/api/pages/blu3mo-public/情報科学の達人/icon' alt='情報科学の達人.icon' height="19.5"/>
- [[Transformer]]のデコーダを使用
- [[Open AI]]が作った[[言語モデル]] ([[GPT]]のv3)
    - めっちゃ巨大なモデル
- [[Common Crawl]]というコーパス、[[書籍]]、[[Wikipedia]]等を使っている
    - 巨大な[[コーパス]]があると、同じ文が繰り返し出るのを防げる = 文を覚えたりしないで訓練できる
- [[言語モデル]]を他の様々なタスクにも応用 (どうやって?)
    - タスクのタイプ
        - [[zero-shot]]型 (やることだけ自然言語で指定)
        - [[few-shot]]型 (やることの指定に加え、実例も指定)
    - ニュース[[記事生成]]
    - [[文章補完]]
    - [[機械翻訳]] (!?) (コーパスに少し(7%)含まれていた他言語の情報だけで、高性能の翻訳ができるように)
    - 苦手: [[合意関係認識]](AがBから推論可能か判定)、二つの文を比較する学習はしていないから?
- #自然言語処理
