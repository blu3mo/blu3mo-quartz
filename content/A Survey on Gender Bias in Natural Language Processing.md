---
title:
 'A Survey on Gender Bias in Natural Language Processing'
---

[https://arxiv.org/pdf/2112.14168.pdf](https://arxiv.org/pdf/2112.14168.pdf)

> Therefore, in this
>  paper, we present an overview of 304 papers on gender bias in natural language processing. We
>  begin with a brief outline our methodology and explore the evolution of the field in popular NLP
>  venues (Â§2). Then, we discuss different definitions of gender in society (Â§3). Further, we define
>  gender bias and sexism in general and in NLP, in particular, incorporating a discussion of their
>  ethical considerations (Â§4). Next, we gather common lexica and datasets curated for research on
>  gender bias (Â§5). Subsequently, we discuss formal definitions of gender bias (Â§6). Then, we discuss
>  methods developed for gender bias detection (Â§7) and mitigation (Â§8).

> Above we have introduced gender bias and sexism as general terms. In the following, we discuss
>  how these biases emerge in natural language and ultimately influence many downstream tasks.
>  Language can be used as a substantial means of expressing gender bias. Gender biases are
>  translated from source data to existing algorithms that may reflect and amplify existing cultural
>  prejudices and inequalities by replicating human behavior and perpetuating bias

> Gender bias is known to perpetuate to models and downstream tasks posing harm for the endusers [[Bolukbasi et al. 2016]]. These harms can emerge as representational and allocational harms and
>  gender gaps.
- å‰æã¨ã—ã¦ä½¿ã†

> Structural bias arises when the construction of sentences shows patterns
>  that are closely tied to the presence of gender bias. It encompasses gender generalisation (i.e.,
>  when a gender-neutral term is assumed to refer to a specific gender-based on some (stereotypical)
>  assumptions) and explicit labeling of sex. On the other hand, contextual bias

> Bias Amplification. Previous research has shown that NLP models are able not only to ==perpetuate biases extant in language, but also to amplify== them [[Zhao et al. 2017]]. In particular, Zhao et al.
>  [[2017]] interpret gender bias as correlations that are potentially amplified by the model and define
>  gender bias towards a ğ‘šğ‘ğ‘› for each word as:

![image](https://gyazo.com/986d795ecd54cd0628526a6fa119b163/thumb/1000)

[[ChatGPT Reading papers]]