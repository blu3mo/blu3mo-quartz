---
title:
 '次元の呪い'
---

<img src='https://scrapbox.io/api/pages/blu3mo-public/情報科学の達人/icon' alt='情報科学の達人.icon' height="19.5"/>パターン認識
- [[特徴量]]を増やしていくと、クラスを分ける線を引く事自体は容易になる
    - ただ、容易になっているのは分割線のパターンが[[次元]]が増えるほど増えていくから
    - その多くの[[パターン]]のうち多くは、未知のデーターには対応できない
- なので、実際にテストデータで試したときの結果は、次元を増やしすぎると下がっていく

- <img src='https://scrapbox.io/api/pages/blu3mo-public/blu3mo/icon' alt='blu3mo.icon' height="19.5"/>[[過学習]]みたいなことが次元数でも起きる
    - 現象自体にあんまり共通点はない?
#機械学習
