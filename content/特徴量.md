---
title:
 '特徴量'
---

<img src='https://scrapbox.io/api/pages/blu3mo-public/情報科学の達人/icon' alt='情報科学の達人.icon' height="19.5"/>パターン認識
- 表現法によって、[[特徴ベクトル]]の次元やパターンの分布も変化
    - ex: 画像を全ピクセルのベクトルではなく、
        - 色合いのヒストグラムを特徴にする
        - 形を特徴にする
        - 行ごとの平均値を特徴にする
    - など、目的によって様々な適した特徴量が考えられる
- 認識にてきした表現を選ぶ必要がある
    - それを頑張るのが[[特徴量エンジニアリング]]
    - もしくは[[Autoencoder]]とかで自動圧縮?
    - 「[[表現学習]]」

---
- 回帰モデルの場合は、X_i

- 特徴量が与える影響が、学習の結果低くなったとしても、その情報が本当に価値がないかは分からない
- 同じ情報が別の特徴量にも[[エンコード]]されてて、その特徴量が使われてないだけかも

#機械学習
