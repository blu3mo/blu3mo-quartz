---
title:
 '特徴量エンジニアリング'
---

- データーの表現の形を模索すること
    - 主に、[[線形モデル]]や[[ナイーブベイズ分類器]]などのシンプルなモデルが影響を受ける
        - 決定木とかはほとんど影響受けない、 NN, [[SVM]], [[最近傍法]]とか受けることもある

- [[データサイエンティスト]]の重要な仕事
- パラメーターの調整より重要なこともある

- [[One-Hot]]
    - 例: job変数の値が{student, engineer, chef}の三種の場合、One-hotで{1,0,0}のように表す
    - それぞれに数字が割り当てられてる場合もある、それでも連続値ではない（順番に意味がない）から、そのまま数値として扱わないように注意

- [[ビニング]]([[離散]]化)
    - 連続値を区切って、クラスにする

- 多項式特徴量
    - [[線形モデル]]とかだと、xというパラメーターがあった時にx^2,x^3とかも追加すると曲線で分離できる
    - 決定木とかだとむしろ性能下げるかも
    - 累乗だけではなく、sin, cos, logとかも使える
        - [[ベルカーブ]]を描くデーターだとよく学習できるから、それに変形するために使ったり

- 自動特徴量選択
    - 役に立つ特徴量を自動で選んで特徴量の数を減らすと、汎化性能が上がる
        - 統計的な相関が高いやつを選ぶとか
        - モデルを学習させて、そのモデルから特徴量の重要度を得て、重要だった特徴量を使ってさらに学習するとか
        - ↑を繰り返すとか

- 専門家の知識を使う
    - 統計データーからじゃ読み取れないけど、人間ならわかる知識もある
    - それを考慮しながら[[特徴量]]エンジニアリングをしていく
#Pythonで始める機械学習
