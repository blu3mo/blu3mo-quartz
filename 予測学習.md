---
title: 予測学習
---

<img src='https://scrapbox.io/api/pages/blu3mo-public/情報科学の達人/icon' alt='情報科学の達人.icon' height="19.5"/>講義

* 普通に考えると、感覚から動作へのマップを作ろうと思ってしまう
  
  * 例: ものを掴む*ロボット*の場合、視界の画像を与えられて、それにどういう運動をするのかという学習をしてしまいがち
* しかし、動作したことによって自分自身の状態・感覚が変わってしまうことも多い（これが本質であることも）
  
  * 自分が*知覚*しているもの全て（環境だけではなく、自分自身の感覚(*身体性*)含む）を全て予測していく、という考え方が有効 #身体知
    * どういう制御をするとどう動くのか、というのも予測の一部
    * どう動くとどう物体が反応するのか、というのも予測の一部
  * end-to-end、一気に全部やっちゃおう
  * それらをそれぞれ頑張って理論ベースで計算するのも可能だけど、めっちゃ複雑・大変
* どう学習するのか
  
  * 環境全て（自分自身含む）の*シーケンス*データを与える
    * データは人間の操作とかで集める?
  * そのシーケンスデータを学習し、ロボットが次の瞬間の環境を予測できるようにする
* <img src='https://scrapbox.io/api/pages/blu3mo-public/blu3mo/icon' alt='blu3mo.icon' height="19.5"/>
[自己](%E8%87%AA%E5%B7%B1.md)の範囲はどこまでか、という*哲学*的議論とも繋がる
  
  * 予測学習したロボットは、すごい自己の範囲が狭い物となる
  * 自己は自分の「意思」（＝予測データ）のみ、それ以外は全て非自己（環境）
* 予測学習は、普通の[\[ニューラルネットワーク\]]([[FNN]])だときつい?
  
  * 一コマ前の状態だけから予測するのは大変
  * 例えば往復運動している物体を予測する場合、
    * あるコマが往路なのか復路なのかは分からない
  * なので、[RNN](RNN.md)が良い（*時系列データー*を持たせられるので）
* 応用例
  
  * [AutoEncoderによる予測学習](AutoEncoder%E3%81%AB%E3%82%88%E3%82%8B%E4%BA%88%E6%B8%AC%E5%AD%A6%E7%BF%92.md)
