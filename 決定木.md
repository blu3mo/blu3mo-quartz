---
title: 決定木
---

* 決定木の分ける場所は、不純度が*最大化*されるところに引く（計算できる）
  
  * *誤り率*とか、*エントロピー*とか、*ジニ係数*で不純度を計算する
* 枝かりをして、[過学習](%E9%81%8E%E5%AD%A6%E7%BF%92.md)防ぐ

良い点

* 結構いろんなスケール/タイプのデーターでいける

* 順応性高い

* *素人にも説明ができる木が作れる*

* 決められた範囲外のことは何もできない

* ![image](https://gyazo.com/d2bcdccc6f4c3a5f72f5686e9e39f392/thumb/1000)
  
  * Tree predictionは、範囲外は何もできていない
* 過剰適合がしやすい

* *ランダムフォレスト*で、ちょっとデーターと特徴量を欠けさせた木をたくさん作る、その多数決をとることでめっちゃ精度高くなる
  
  * [過学習](%E9%81%8E%E5%AD%A6%E7%BF%92.md)も避けられる
  * 一番メジャーな回帰/分類の手法
  * ただ、木のメリットである説明性は減る
* *勾配ブースティング回帰木*もある、パラメーター多いけどより性能良い
  
  * 事前枝刈りをした小さい木をたくさん組み合わせる
    \#Pythonで始める機械学習
