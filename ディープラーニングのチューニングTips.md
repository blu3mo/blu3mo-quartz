---
title: ディープラーニングのチューニングTips
---

*情報α課題2: CIFAR10でCNNを訓練*で思ったこと

* 「①モデルを調整して精度を高める」と「②*汎化性能*を高める」の両輪を回していく、みたいな感じのプロセスだな〜と思った
  * accuracyとvalidation_accuracyのグラフをみて二輪の内進めるべき方を進める、という作業の繰り返しだった
  * 正しいやり方なのかは分からんけど

from *東大1S情報α*
ディープラーニングのテクニック

* パラメータ初期値の決め方
  * どういう初期値が良い?
    * 学習後は0を中心に分布するので、元から0を中心にすると良い
    * あと、次元が多いほどばらつきは小さい
    * あとは、いい感じの正規分布でバラつけとけば良い
      * この「良い感じの正規分布」が*Xavierの正規分布*とか*Heの正規分布*
        * 分布範囲が違う
* *勾配クリッピング*
  * 勾配の上限を定めておこう、というやつ
* 過学習防ぐ
  * [正則化](%E6%AD%A3%E5%89%87%E5%8C%96.md)
    * 大きいパラメータθを避けるため
  * *ドロップアウト(深層学習)*
    * ランダムに枝を消すこと
    * 最近あんまり使わないらしい
  * 早期終了
    * なんかもう普通に過学習する前に止めちゃおう、というやつ
  * *バッチ正規化*
    * *ミニバッチ*ごとのデータのばらつきを補正
    * バッチデータの平均値・分散を全体データを同じにする、という感じかな?
      * ミクロなばらつきによって*確率的勾配降下法*ができると同時に、マクロ的には全体集合と同じ感じになって嬉しい
    * なんでうまくいってるかは分からん
      * なんなら本来の目的（全体データとのずれを減らす）はあんまり意味がない
      * けど、なんでか分からないけど損失関数のでこぼこがなだらかになるから使う、みたいな感じらしい
        * 魔法〜〜<img src='https://scrapbox.io/api/pages/blu3mo-public/blu3mo/icon' alt='blu3mo.icon' height="19.5"/>
* これらのテクニックは色々あるけど、
  * ベストな方法が分からないので、付け合わせのテクニックの組み合わせで実用上対処する感じ
  * どれを使えば良いのかはまあ*トライアンドエラー*
  * とりあえず*バッチ正規化*が特に強いらしいので覚えておきたい
